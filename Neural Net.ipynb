{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydot as pyd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras import models\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekday of Fecha Referencia</th>\n",
       "      <th>Day of Fecha Referencia</th>\n",
       "      <th>Month of Fecha Referencia</th>\n",
       "      <th>Giros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weekday of Fecha Referencia  Day of Fecha Referencia  \\\n",
       "id                                                         \n",
       "1                             1                        1   \n",
       "2                             1                        1   \n",
       "3                             1                        1   \n",
       "4                             1                        1   \n",
       "5                             1                        1   \n",
       "\n",
       "    Month of Fecha Referencia  Giros  \n",
       "id                                    \n",
       "1                           1   1115  \n",
       "2                           2   5934  \n",
       "3                           4  13417  \n",
       "4                           5   2827  \n",
       "5                           6  12283  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./output/giros_train_numeric.csv', index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=[\"Giros\"])\n",
    "y = train[\"Giros\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder()\n",
    "y = enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 7.6034 - accuracy: 0.0000e+00 - val_loss: 7.6222 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 7.5183 - accuracy: 0.0011 - val_loss: 7.8580 - val_accuracy: 0.0023\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.4159 - accuracy: 0.0029 - val_loss: 8.6527 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.3188 - accuracy: 0.0017 - val_loss: 9.5814 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.2647 - accuracy: 0.0040 - val_loss: 10.3205 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.2090 - accuracy: 0.0029 - val_loss: 10.8984 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.1599 - accuracy: 0.0046 - val_loss: 11.4835 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.1035 - accuracy: 0.0029 - val_loss: 12.1018 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.0418 - accuracy: 0.0063 - val_loss: 12.5970 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.9754 - accuracy: 0.0057 - val_loss: 13.1512 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.9060 - accuracy: 0.0068 - val_loss: 13.5014 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.8337 - accuracy: 0.0068 - val_loss: 13.7793 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.7423 - accuracy: 0.0074 - val_loss: 14.0435 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.6631 - accuracy: 0.0091 - val_loss: 14.2298 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 6.5851 - accuracy: 0.0091 - val_loss: 14.3621 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.4787 - accuracy: 0.0103 - val_loss: 14.4520 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.4023 - accuracy: 0.0103 - val_loss: 14.5122 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.2966 - accuracy: 0.0120 - val_loss: 14.5691 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.2026 - accuracy: 0.0120 - val_loss: 14.6125 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.1140 - accuracy: 0.0131 - val_loss: 14.6512 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.0117 - accuracy: 0.0131 - val_loss: 14.6865 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.9226 - accuracy: 0.0137 - val_loss: 14.7148 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 5.8339 - accuracy: 0.0148 - val_loss: 14.7396 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.7590 - accuracy: 0.0131 - val_loss: 14.7715 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 5.6903 - accuracy: 0.0125 - val_loss: 14.7939 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.5946 - accuracy: 0.0200 - val_loss: 14.8176 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.5003 - accuracy: 0.0228 - val_loss: 14.8455 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.4434 - accuracy: 0.0188 - val_loss: 14.8711 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.3892 - accuracy: 0.0234 - val_loss: 14.8992 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.2816 - accuracy: 0.0245 - val_loss: 14.9234 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.2003 - accuracy: 0.0245 - val_loss: 14.9480 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.1948 - accuracy: 0.0240 - val_loss: 14.9771 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.1140 - accuracy: 0.0205 - val_loss: 15.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.0745 - accuracy: 0.0217 - val_loss: 15.0258 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 4.9889 - accuracy: 0.0262 - val_loss: 15.0596 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 4.9418 - accuracy: 0.0319 - val_loss: 15.0767 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 4.8879 - accuracy: 0.0268 - val_loss: 15.1097 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.8639 - accuracy: 0.0251 - val_loss: 15.1272 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.7976 - accuracy: 0.0297 - val_loss: 15.1520 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.7709 - accuracy: 0.0314 - val_loss: 15.1675 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.7192 - accuracy: 0.0291 - val_loss: 15.1937 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6899 - accuracy: 0.0285 - val_loss: 15.2217 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6531 - accuracy: 0.0280 - val_loss: 15.2434 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6506 - accuracy: 0.0257 - val_loss: 15.2621 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6092 - accuracy: 0.0308 - val_loss: 15.2766 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.5540 - accuracy: 0.0291 - val_loss: 15.2945 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.5207 - accuracy: 0.0308 - val_loss: 15.3109 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 4.5438 - accuracy: 0.0308 - val_loss: 15.3251 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 4.4877 - accuracy: 0.0274 - val_loss: 15.3445 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 4.4375 - accuracy: 0.0337 - val_loss: 15.3549 - val_accuracy: 0.0000e+00\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 15.3549 - accuracy: 0.0000e+00\n",
      "\n",
      "\n",
      "Resultados:  [15.354927062988281, 0.0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_classes = y.shape[1]\n",
    "inshape = (X_train.shape[1],)\n",
    "\n",
    "\n",
    "model = models.Sequential()  #creates the neural network layers:\n",
    "\n",
    "model.add(layers.Dense(64, activation='elu', input_shape=inshape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dense(64, activation='elu'))\n",
    "\n",
    "model.add(layers.Dense(number_classes, activation='sigmoid'))\n",
    "model.compile(optimizer='adamax',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=50,\n",
    "        batch_size=20,\n",
    "        validation_data=(X_test, y_test))\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"\\n\")\n",
    "print(\"Resultados: \",results)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.1979788e-18, 1.6612667e-14, 7.3570122e-10, ..., 9.9391451e-10,\n",
       "        2.2657424e-21, 2.5378816e-19],\n",
       "       [2.1751163e-10, 8.7514258e-16, 1.6170699e-09, ..., 5.6553545e-10,\n",
       "        6.8459227e-12, 2.6731877e-15],\n",
       "       [2.9973112e-21, 1.7851934e-14, 7.3161925e-09, ..., 4.5047108e-09,\n",
       "        1.6736912e-22, 3.9079183e-21],\n",
       "       ...,\n",
       "       [1.0661739e-16, 5.4450262e-17, 1.6911366e-09, ..., 2.2236017e-09,\n",
       "        4.5094039e-17, 5.5043385e-24],\n",
       "       [4.4802595e-02, 8.4980472e-27, 3.2802927e-11, ..., 1.0268174e-11,\n",
       "        7.7566755e-04, 1.4390125e-13],\n",
       "       [4.3028641e-16, 1.1981029e-12, 2.7660567e-08, ..., 2.0647381e-08,\n",
       "        1.2298359e-17, 8.3949295e-22]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8718,  3813,  5073,  4941, 10963,  6606,  7188,  1924,  2002,\n",
       "        4331, 11894,  7240,  1676,  3720,  4802,  3411,  3300,  6209,\n",
       "        3900,  5024,  2324,  2492,  4741,  9292,  1990,  1997, 13598,\n",
       "        3863,  9294,  1718,  3649,  5093,  6424,  8712,  7807,  2307,\n",
       "        7512,  7653,  2046,  5098,  6816,  1304,  5055,  8679,  5580,\n",
       "        8309,  6743,  9215,  2912, 12254,  5505,  4056,  2590,  7240,\n",
       "        1588,  3676,  3900,  3649,  1836,  4230,  6891,  4421, 12032,\n",
       "        2721,  9037,  3664,  6678, 11449,  2080, 14388,  4371,  6539,\n",
       "        2409,  6097, 12797,  1249,  8029,  1829,  4941,  4792, 11449,\n",
       "        3048, 10618, 12032,  3364,  5623,  4576,  5278,  8366, 10735,\n",
       "        1615,  7807,  8128,  4421,  9920,  5544,  2670,  1304, 12375,\n",
       "        9017,  7465, 10891,  6444,  6251,  4860, 13582,  4834,  7532,\n",
       "        8718,  8321,  4135,  9915,  7512,  4322,  4858,  2828, 10522,\n",
       "        6691,  4401,  1587,  9030,  1883,  2840,  3428,  4249,  3258,\n",
       "        4677,  7083,  3828,  7097,  6200,  4277, 12207,  8980,  9037,\n",
       "       10319,  1249,  7181,  6150,  2164,  1874,  8414,  2286,  8321,\n",
       "        9178, 11936, 11984,  6018,  4691,  3281,  8128,  5998,  3205,\n",
       "        5821,  3223,  5091,  5082,  2086,  1143,  2844,  1568,  4465,\n",
       "        3430,  2269,  3044,  7033,  1673,  5645,  4659,  4472,  4387,\n",
       "        5332,  4885,  4997,  4493,  8945,  5896,  2779,  3197,  2374,\n",
       "        7935,  4955,  4528,  1642,  2432,  2826,  3173,  3524,  4978,\n",
       "       10831,  6539,  2944,  5643, 11894,  9215,  7334,  5317,  1883,\n",
       "        1425,  4139,  3062,  3554,  9292, 12756,  5278,  3706,  2692,\n",
       "        3251,  8754,  4253, 11571,  2839, 11242,  7966,  8793,  3424,\n",
       "        6455,   631, 12375, 12669,  3798,  3413,  1990,  9294,  4363,\n",
       "        2447,  6459,  2549,  6716,  4610,  2633,   662, 10125,  1921,\n",
       "        6405,  7083,  4792,  6097,  2692,  1921,  2503,  4927,  8114,\n",
       "        4941,  7792,  2445,  2562,  1567,  4706,  3308,  3413,  5859,\n",
       "        2817,  2775,  7662,  4049,  4924,  8945,  1100,  1764, 11191,\n",
       "        4858,  2849,  1799,  2179,  5708,  4574,  4737, 10319,  5900,\n",
       "        4687,  7259,  9915,  4352,  5276, 12631,  2719,  9527,  4802,\n",
       "        3649,  6603,  4245,  7288,  8549,  3250,  9915,  5623,  1836,\n",
       "       12165,  6150,  7824,  7155,  1343,  6810,  2642,  5252,  5654,\n",
       "       11088,  4687,  2158,  4941,  8321,  3237,  6603,  1876,  1276,\n",
       "        3237,  4216,  7457,  5053,  4679,  1755,  7765,  4493,  4925,\n",
       "        3424,  3197,  4363,  8628,  8718,  1686,  5252,  1040,  4927,\n",
       "        7512,  7188,  5189,  2562,  4941,  1447, 11872,  4097,  9868,\n",
       "       11242, 12315,  5091,  7922,  3316,  6691,  2944, 10517,  2894,\n",
       "        6713,  4426,  3556,  1466,  2243,  6385,  6539,  3281,  8628,\n",
       "       10434,  2378,  2867,  7439,  4801,  1028,  3978,  3379,  7209,\n",
       "       11894, 10250,  6847,  7650, 10349,  6776,  4494,  1446,  3382,\n",
       "        8021,  7485,  3424,  5203,  3605,  8549,  4236,  2184,  4216,\n",
       "        2433,  7181, 12768,  5708,  2447,  4386,  3258,  6955,  9765,\n",
       "        5384,  4887,  6455,  4997,  4474,  4221,  2762,  3500,  5859,\n",
       "        5286,  1588,  7824,  2363,  6878,  4420,  6405,  6419,  4677,\n",
       "        6514,  8025,  2158, 12165,  4221,  8914,  1587, 12254,  6405,\n",
       "        8115, 11191,  9755,  2286, 12254,  9955,  6514,  3113,  2129,\n",
       "       10963,  4055,  8309,  2600,  5937,  2610,  2944,  2403, 12444,\n",
       "        1924,  2718,  1638,  5189,  1425,  6081,  1695])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = enc.inverse_transform(y_pred)\n",
    "prediction = prediction.reshape(prediction.shape[0])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2692,  2495,  1853,  3747,  3417,  7557, 11155,  1254,  6313,\n",
       "        1197,  6118,  5923,  2678,  5051,  1578,  3515,  9898,  4941,\n",
       "        2779,  2164,  5043,  1570,  3776,  2423,  2690,  6222,  2877,\n",
       "        2633, 10634,  2207,  5408, 13945,  3374,  5016,  6776,  2994,\n",
       "        7490,  2240,  5427,  5434,  2121,  1330,  3966,  2790,  4311,\n",
       "        2301,  3126,  4341,  4083,  9191,  4215,  7633, 10700,  5540,\n",
       "        1727,  2471,  9107,  3148,  6109,  8187,  4533,  5896,  9412,\n",
       "        9375,  5249,  2237, 10666,  6059,  8435,  7566,  5157,  2212,\n",
       "        1614,  2404,  7762,  3357,  3026,  3790,  4011,  4966,  4635,\n",
       "        1824,  4597,  3956,  4250,  2577,  1601,  9414,  1963,  6102,\n",
       "        3798,  3418,  5965,  8213,  2785,  5778,  3923,  2030, 10811,\n",
       "        7518, 15360, 10246,  4790,  2357,  3266,  3479,  8233,  2766,\n",
       "        3405,  5850,  2322,  6122,  5739,  2735,  2008,  5219,  3787,\n",
       "       13813,  5965,  3010,  6894,  6490,  8033,  3743,  7484,  4747,\n",
       "        2476,  1881,  6618,  3431,  2018,  9253, 10416,  7282,  5274,\n",
       "        5142,  4113, 12024,  8675,  2613,  3840, 14378,  8832,  5573,\n",
       "       10162, 10942,  6919,  8569,  6153,  3939, 12340,  4409,  3991,\n",
       "        7794,  4257,  9688,  6410,  4231,  1829,  8108,  2782,  3754,\n",
       "        3304,  8667, 10087,  3932,  6751,  5351,  5863,  3917,  4474,\n",
       "        1814,  6126,  7166,  3432, 10265,  6084,  4068,  8693,  4705,\n",
       "        1931, 10141,  3555,  5086,   694,  4068,  4456,  1408,  1867,\n",
       "        3220,  7664,  8485,  2379,  7152,  9002,  7109, 13547,  2645,\n",
       "        2510,  2572,  2498,  1223,  5201,  9976, 15506,  2613,  2297,\n",
       "        2003,  8663,  4612,  6724,  9284,  1932,  7771,  2764,  2222,\n",
       "        9061,  6052,  8797,  3596,  5308,  5145,  6399,  5533,  4364,\n",
       "        8913,  4027,  7357,  5547,  7060,  5896,  5517,  5782,  2157,\n",
       "        6396,  1965,  1429,  1797,  7197,  5333,  2962,  2704,  5393,\n",
       "        6385,  6414,  1207,  1725,  1077,  6340,  1686,  5778,  5462,\n",
       "        8676, 11650,  6556,  2098,  4036,  6034,  3843,  2300,  5122,\n",
       "        1603,  4037,  6395,  7479,  3983,  2770,  5875,  4701,  3608,\n",
       "        3334,  7486,  6095,  2054,  4630,  9916,  1236,  8169,  4578,\n",
       "        1721, 13499,  6809,  6233,  5006,  3083, 11321,  3645,  5002,\n",
       "        3428,  4095,  4880,  2931,  4603,  4734,  7480,  3020,  5934,\n",
       "       11641,  4798,  2528,  9845,  4064,  2139,  7165,  1398,  1160,\n",
       "        1963,  1378,  2716,  4826,  7609,  2663,  2943,  5337,  4921,\n",
       "        2297, 14496,  7726,  8566,  3212,  2100,  3727,  2959,  3880,\n",
       "        2588,  6173,  1515,  7013,  6265,  5571,  3945,  2031,  8110,\n",
       "        5348, 10454,  2360,  2400,  1736,  5088,  5215,  6175,  4444,\n",
       "        4419,  6254,  3933,  6084,  4238,  8074,  4257,  3986, 13438,\n",
       "        6094,  1761,  6660,  4808,  5727,  2782,  2780,  8223,  7665,\n",
       "        5906,  3503, 10384,  2328,  7529,  3956,  2692,  6863,  1267,\n",
       "        9979,  6298,  4369, 10307,  2836,  4013,  3953,  6926,  1934,\n",
       "        1793,  6897,  4927,  1927,  5212,  2209,  3330, 12232,  2980,\n",
       "        9090,  3846,  8295,  4533,  1977, 15363,  6019,  5098, 11061,\n",
       "        2259,  2503, 14109,  1646,  6628,  1331,  6354,  4856, 10012,\n",
       "        3863,  2136,  5268,  7340,  6165,  3663,  4705,  3075,  1944,\n",
       "        4153,  8254,  8940,  2925,  6601,  3383, 10547,  9309,  5238,\n",
       "        8992,  3239,  8898,  3592, 11403,  2247,  3663,  7612, 12397,\n",
       "        3500,  1829,  1235,  4834,  2024,  8627,  1488])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = enc.inverse_transform(y_test)\n",
    "y_test = y_test.reshape(y_test.shape[0])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8718</td>\n",
       "      <td>2692</td>\n",
       "      <td>6026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3813</td>\n",
       "      <td>2495</td>\n",
       "      <td>1318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5073</td>\n",
       "      <td>1853</td>\n",
       "      <td>3220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4941</td>\n",
       "      <td>3747</td>\n",
       "      <td>1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10963</td>\n",
       "      <td>3417</td>\n",
       "      <td>7546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>1638</td>\n",
       "      <td>1235</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>5189</td>\n",
       "      <td>4834</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1425</td>\n",
       "      <td>2024</td>\n",
       "      <td>-599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>6081</td>\n",
       "      <td>8627</td>\n",
       "      <td>-2546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1695</td>\n",
       "      <td>1488</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>439 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prediction  ground_truth  diff\n",
       "0          8718          2692  6026\n",
       "1          3813          2495  1318\n",
       "2          5073          1853  3220\n",
       "3          4941          3747  1194\n",
       "4         10963          3417  7546\n",
       "..          ...           ...   ...\n",
       "434        1638          1235   403\n",
       "435        5189          4834   355\n",
       "436        1425          2024  -599\n",
       "437        6081          8627 -2546\n",
       "438        1695          1488   207\n",
       "\n",
       "[439 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame({'prediction': prediction,\n",
    "                              'ground_truth': y_test,\n",
    "                              'diff': prediction - y_test})\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"number_classes = y.shape[1]\n",
    "inshape = (X_train.shape[1],)\n",
    "\n",
    "\n",
    "model = models.Sequential()  #creates the neural network layers:\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=inshape))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(number_classes, activation='softmax'))\n",
    "model.compile(optimizer='Nadam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=50,\n",
    "        batch_size=20,\n",
    "        validation_data=(X_test, y_test))\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"\\n\")\n",
    "print(\"Resultados: \",results)\n",
    "print(\"\\n\")\n",
    "\n",
    "23.8%\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
